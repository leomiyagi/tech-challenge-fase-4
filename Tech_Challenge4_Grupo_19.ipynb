{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wJjMKvNePgK",
        "outputId": "87ce3c5c-f554-4339-9a68-4006ee81625b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (11.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.17.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.5.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.0.3)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.24.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.11)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.4.20)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.12.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.16.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.8.30)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations->insightface) (3.10.10)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface, fire\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1055393 sha256=278bc5a030e175f14a4573ca65eaa6f6c08f639df30838d8456e9de09b3213fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=883759154c15a0b2e7f4337886d1fed4dc1dcaae94a8a0cb675a118dfedc70d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built insightface fire\n",
            "Installing collected packages: onnx, lz4, humanfriendly, gunicorn, fire, sounddevice, mtcnn, coloredlogs, onnxruntime, flask-cors, mediapipe, insightface, retina-face, deepface\n",
            "Successfully installed coloredlogs-15.0.1 deepface-0.0.93 fire-0.7.0 flask-cors-5.0.0 gunicorn-23.0.0 humanfriendly-10.0 insightface-0.7.3 lz4-4.3.3 mediapipe-0.10.18 mtcnn-1.0.0 onnx-1.17.0 onnxruntime-1.20.1 retina-face-0.0.17 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface insightface tqdm onnxruntime mediapipe scikit-learn numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Ov66-3Deoxa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "from insightface.app import FaceAnalysis\n",
        "import uuid\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mediapipe.python.solutions.hands import Hands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR9rZB2Km7il"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E5xYtLbpSlhG"
      },
      "outputs": [],
      "source": [
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6HQv_4qetWB"
      },
      "outputs": [],
      "source": [
        "def generate_summary(emotion_counts, total_frames, output_path):\n",
        "    # Exibir Relatório no Console\n",
        "    print(\"RELATÓRIO:\")\n",
        "\n",
        "    # Exibir o total de frames analisados\n",
        "    print(f\"\\nTotal de frames analisados: {total_frames}\")\n",
        "\n",
        "    # Exibir o resumo das emoções detectadas\n",
        "    print(\"\\nResumo das emoções detectadas:\")\n",
        "    for emotion, count in emotion_counts.items():\n",
        "        print(f\"{emotion}: {count} ocorrências\")\n",
        "\n",
        "    # Exibir o número de anomalias detectadas (categorias 'Unknown')\n",
        "    anomalies = emotion_counts.get(\"Unknown\", 0)\n",
        "    print(f\"\\nNúmero de anomalias detectadas: {anomalies}\")\n",
        "\n",
        "    # Criar o arquivo de relatório\n",
        "    report_path = os.path.join(os.path.dirname(output_path), 'relatorio_analise.txt')\n",
        "\n",
        "    with open(report_path, 'w') as report_file:\n",
        "        # Escrever o total de frames analisados\n",
        "        report_file.write(f\"Total de frames analisados: {total_frames}\\n\")\n",
        "\n",
        "        # Escrever o resumo das emoções detectadas\n",
        "        report_file.write(\"\\nResumo das emoções detectadas:\\n\")\n",
        "        for emotion, count in emotion_counts.items():\n",
        "            report_file.write(f\"{emotion}: {count} ocorrências)\\n\")\n",
        "\n",
        "        # Escrever o número de anomalias detectadas\n",
        "        report_file.write(f\"\\nNúmero de anomalias detectadas: {anomalies}\\n\")\n",
        "\n",
        "    print(f\"\\nRelatório salvo em: {report_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A847rr7sevtz",
        "outputId": "f6101337-a8ca-47eb-bc4a-cee5ae6eea99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pasta criada: /content/detected_faces\n"
          ]
        }
      ],
      "source": [
        "def criar_pasta_para_rostos(diretorio=\"detected_faces\"):\n",
        "    # Obter o caminho absoluto\n",
        "    caminho_absoluto = os.path.abspath(diretorio)\n",
        "\n",
        "    # Criar a pasta se ela não existir\n",
        "    if not os.path.exists(caminho_absoluto):\n",
        "        os.makedirs(caminho_absoluto)\n",
        "        print(f\"Pasta criada: {caminho_absoluto}\")\n",
        "    else:\n",
        "        print(f\"Pasta já existente: {caminho_absoluto}\")\n",
        "        return caminho_absoluto\n",
        "\n",
        "# Exemplo de uso\n",
        "pasta_rostos = criar_pasta_para_rostos()\n",
        "\n",
        "def ajustar_limites_rosto(box, width, height):\n",
        "\n",
        "    x1, y1, x2, y2 = box\n",
        "    x1, y1 = max(0, x1), max(0, y1)\n",
        "    x2, y2 = min(width, x2), min(height, y2)\n",
        "    return x1, y1, x2, y2\n",
        "def rastrear_ou_criar_id(box, face_trackers, proximo_id):\n",
        "\n",
        "    for existing_id, tracker_info in face_trackers.items():\n",
        "        tracked_box, _ = tracker_info\n",
        "        iou = sobreposicao(box, tracked_box)\n",
        "        if iou > 0.5:\n",
        "            return existing_id, proximo_id, face_trackers\n",
        "\n",
        "    face_id = proximo_id\n",
        "    proximo_id += 1\n",
        "    return face_id, proximo_id, face_trackers\n",
        "#face_roi, face_id, Rastreados, diretorio_saida\n",
        "\n",
        "def salvar_rosto(face_roi, face_id, Rastreados, diretorio_saida):\n",
        "\n",
        "    if face_id not in Rastreados:\n",
        "        Rastreados.add(face_id)\n",
        "        face_image_path = os.path.join(diretorio_saida, f\"face_{face_id}.jpg\")\n",
        "        cv2.imwrite(face_image_path, cv2.cvtColor(face_roi, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def sobreposicao(boxA, boxB):\n",
        "    # Calcular a interseção sobre união (IOU) entre dois retângulos\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def salvar_excel(emotions_per_id, output_path):\n",
        "    # Converter o dicionário em um DataFrame\n",
        "    data = [{\"ID\": face_id, \"Emoção Predominante\": emotion} for face_id, emotion in emotions_per_id.items()]\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Caminho para o arquivo Excel\n",
        "    excel_path = os.path.join(os.path.dirname(output_path), 'analise_emocoes.xlsx')\n",
        "\n",
        "    # Salvar o DataFrame no Excel\n",
        "    df.to_excel(excel_path, index=False)\n",
        "    print(f\"Arquivo Excel salvo em: {excel_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9c0_LeNexa0"
      },
      "outputs": [],
      "source": [
        "def detect_emotions(video_path, output_path):\n",
        "    # Capturar vídeo do arquivo especificado\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Verificar se o vídeo foi aberto corretamente\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erro ao abrir o vídeo.\")\n",
        "        return\n",
        "\n",
        "    # Obter propriedades do vídeo\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Definir o codec e criar o objeto VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Inicializar dicionário para contabilizar emoções\n",
        "    emotion_counts = {}\n",
        "    emotions_per_id = {}\n",
        "    pose_data = []\n",
        "    anomalies_detected = 0\n",
        "    total_frames_analyzed = 0\n",
        "    frames_sem_rosto = 0\n",
        "    frames_so_maos = 0\n",
        "\n",
        "    #prev_gray = None  # Frame anterior em escala de cinza\n",
        "\n",
        "    app = FaceAnalysis()\n",
        "    app.prepare(ctx_id=0)  # Use ctx_id=-1 for CPU\n",
        "\n",
        "    diretorio_saida=\"detected_faces\"\n",
        "\n",
        "    criar_pasta_para_rostos(diretorio=diretorio_saida)\n",
        "\n",
        "    Rastreador = {}\n",
        "    proximo_id = 1\n",
        "    Rastreados = set()\n",
        "\n",
        "    isolation_forest = IsolationForest(contamination=0.1)\n",
        "\n",
        "    maos = Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "    maos_sobre_a_face = 0\n",
        "    # Loop para processar cada frame do vídeo\n",
        "    for _ in tqdm(range(total_frames), desc=\"Processando vídeo\"):\n",
        "        # Ler um frame do vídeo\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Se não conseguiu ler o frame (final do vídeo), sair do loop\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        rgb_frame = frame[:, :, ::-1]\n",
        "        faces = app.get(rgb_frame)\n",
        "        hands_results = maos.process(rgb_frame)\n",
        "\n",
        "        results = pose.process(rgb_frame)\n",
        "\n",
        "        if len(faces) == 0:\n",
        "            frames_sem_rosto += 1\n",
        "\n",
        "            # Verificar se há mãos detectadas\n",
        "            if hands_results.multi_hand_landmarks:\n",
        "                frames_so_maos += 1\n",
        "                cv2.putText(frame, \"Hands only detected\", (10, height - 50),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
        "            elif results.pose_landmarks:\n",
        "                # Verificar landmarks dos braços (cotovelos e pulsos)\n",
        "                landmarks = results.pose_landmarks.landmark\n",
        "                left_elbow = landmarks[13]  # Cotovelo esquerdo\n",
        "                right_elbow = landmarks[14]  # Cotovelo direito\n",
        "                left_wrist = landmarks[15]  # Pulso esquerdo\n",
        "                right_wrist = landmarks[16]  # Pulso direito\n",
        "\n",
        "                # Calcular posições absolutas no frame\n",
        "                arm_landmarks = [\n",
        "                    (left_elbow.x, left_elbow.y),\n",
        "                    (right_elbow.x, right_elbow.y),\n",
        "                    (left_wrist.x, left_wrist.y),\n",
        "                    (right_wrist.x, right_wrist.y),\n",
        "                ]\n",
        "\n",
        "                arm_positions = [\n",
        "                    (int(lm[0] * width), int(lm[1] * height)) for lm in arm_landmarks\n",
        "                ]\n",
        "\n",
        "                # Marcar braços nos frames\n",
        "                for pos in arm_positions:\n",
        "                    cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
        "\n",
        "                cv2.putText(frame, \"Arms only detected\", (10, height - 80),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "        # Exibir contagem de frames no vídeo\n",
        "        cv2.putText(frame, f\"No Faces: {frames_sem_rosto}, Hands Only: {frames_so_maos}\",(10, height - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "        # Manter o controle do número de faces detectadas\n",
        "        if 'prev_num_faces' not in locals():\n",
        "            prev_num_faces = 0\n",
        "\n",
        "        num_faces = len(faces)\n",
        "\n",
        "        faces_text = f\"Number of faces changed from {prev_num_faces} to {num_faces}\"\n",
        "        cv2.putText(frame, faces_text, (10, height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "        if num_faces != prev_num_faces:\n",
        "            prev_num_faces = num_faces\n",
        "\n",
        "        for face in faces:\n",
        "            box = face.bbox.astype(int)\n",
        "            x1, y1, x2, y2=ajustar_limites_rosto(box, width, height)\n",
        "\n",
        "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
        "\n",
        "            face_roi = rgb_frame[y1:y2, x1:x2]\n",
        "\n",
        "            ja_existe = False\n",
        "            id_face = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if face_roi.size == 0:\n",
        "                print(f\"Rosto inválido detectado no frame {_}, ignorando.\")\n",
        "                continue\n",
        "            else:\n",
        "                face_id, proximo_id, Rastreador = rastrear_ou_criar_id(box, Rastreador, proximo_id)\n",
        "                Rastreador[face_id] = ((x1, y1, x2, y2), _)\n",
        "                salvar_rosto(face_roi, face_id, Rastreados, diretorio_saida)\n",
        "\n",
        "            try:\n",
        "                # Chamar a função para detectar anomalias\n",
        "                #anomalies_detected = detectar_anomalia_mao(\n",
        "                #    prev_gray, face_roi, x1, y1, frame, anomalies_detected\n",
        "                #)\n",
        "\n",
        "                analysis = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "                if isinstance(analysis, list) and len(analysis) > 0:\n",
        "                    dominant_emotion = analysis[0]['dominant_emotion']\n",
        "                else:\n",
        "                    dominant_emotion = \"Unknown\"\n",
        "\n",
        "            except Exception as e:\n",
        "                dominant_emotion = \"Error\"\n",
        "                print(f\"Error analyzing emotion: {e}\")\n",
        "\n",
        "            # Atualizar contador de emoções\n",
        "            if dominant_emotion not in emotion_counts:\n",
        "                emotion_counts[dominant_emotion] = 0\n",
        "            emotion_counts[dominant_emotion] += 1\n",
        "\n",
        "            emotions_per_id[face_id] = dominant_emotion\n",
        "\n",
        "            cv2.putText(frame, f\"ID:{face_id} - {dominant_emotion}\",(box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 255, 255), 2)\n",
        "\n",
        "            if hands_results.multi_hand_landmarks:\n",
        "                      for hand_landmarks in hands_results.multi_hand_landmarks:\n",
        "                          hand_points = [(int(landmark.x * width), int(landmark.y * height))\n",
        "                                        for landmark in hand_landmarks.landmark]\n",
        "\n",
        "                          for point in hand_points:\n",
        "                              px, py = point\n",
        "                              if x1 <= px <= x2 and y1 <= py <= y2:\n",
        "                                  maos_sobre_a_face += 1\n",
        "                                  cv2.putText(frame, \"Hand over face detected\", (10, height - 50),\n",
        "                                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)\n",
        "                                  break\n",
        "\n",
        "    # Exibir contagem no frame\n",
        "            cv2.putText(frame, f\"Hands over face: {maos_sobre_a_face}\", (10, height - 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "            #prev_gray = gray_frame  # Atualizar o frame anterior\n",
        "\n",
        "        # Escrever o frame processado no arquivo de vídeo de saída\n",
        "        out.write(frame)\n",
        "\n",
        "        # Analisar dados de pose para detectar anomalias\n",
        "    if len(pose_data) > 10:\n",
        "        pose_data = np.array(pose_data)\n",
        "        anomaly_labels = isolation_forest.fit_predict(pose_data)\n",
        "        anomalies_detected = np.sum(anomaly_labels == -1)\n",
        "\n",
        "    with open(os.path.join(os.path.dirname(output_path), 'relatorio_analise.txt'), 'a') as report_file:\n",
        "        report_file.write(f\"\\nNúmero de anomalias detectadas (movimentos anômalos): {anomalies_detected}\\n\")\n",
        "\n",
        "    # Chamar a função para gerar o relatório\n",
        "    generate_summary(emotion_counts, total_frames, output_path)\n",
        "\n",
        "    salvar_excel(emotions_per_id, output_path)\n",
        "\n",
        "    # Liberar a captura de vídeo e fechar todas as janelas\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEOn56zZe59J",
        "outputId": "5530511c-7b51-4c67-e6b9-d099225e26d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 281857/281857 [00:04<00:00, 62918.18KB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "Pasta já existente: /content/detected_faces\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessando vídeo:   0%|          | 0/3326 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24-11-27 22:38:40 - facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 86.1MB/s]\n",
            "Processando vídeo: 100%|██████████| 3326/3326 [1:15:51<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RELATÓRIO:\n",
            "\n",
            "Total de frames analisados: 3326\n",
            "\n",
            "Resumo das emoções detectadas:\n",
            "fear: 1100 ocorrências\n",
            "angry: 290 ocorrências\n",
            "neutral: 695 ocorrências\n",
            "sad: 1494 ocorrências\n",
            "surprise: 195 ocorrências\n",
            "happy: 922 ocorrências\n",
            "disgust: 1 ocorrências\n",
            "\n",
            "Número de anomalias detectadas: 0\n",
            "\n",
            "Relatório salvo em: /content/drive/MyDrive/TechChallenge4/relatorio_analise.txt\n",
            "Arquivo Excel salvo em: /content/drive/MyDrive/TechChallenge4/analise_emocoes.xlsx\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bae7d9ba3425>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Chamar a função para detectar emoções no vídeo e salvar o vídeo processado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdetect_emotions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-18f911082f21>\u001b[0m in \u001b[0;36mdetect_emotions\u001b[0;34m(video_path, output_path)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ],
      "source": [
        "script_dir = os.getcwd()\n",
        "input_video_path = \"/content/drive/MyDrive/TechChallenge4/Video_tc.mp4\"\n",
        "output_video_path = \"/content/drive/MyDrive/TechChallenge4/movimentos3.mp4\"  # Nome do vídeo de saída\n",
        "\n",
        "# Chamar a função para detectar emoções no vídeo e salvar o vídeo processado\n",
        "detect_emotions(input_video_path, output_video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvF6cUFrT9uB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}